PEMS04
Trainset:	x-(10181, 12, 307, 3)	y-(10181, 12, 307, 1)
Valset:  	x-(3394, 12, 307, 3)  	y-(3394, 12, 307, 1)
Testset:	x-(3394, 12, 307, 3)	y-(3394, 12, 307, 1)

Random seed = 1
--------- STHDformer ---------
{
    "num_nodes": 307,
    "in_steps": 12,
    "out_steps": 12,
    "train_size": 0.6,
    "val_size": 0.2,
    "time_of_day": true,
    "day_of_week": true,
    "lr": 0.001,
    "weight_decay": 0.0005,
    "milestones": [
        15,
        30,
        50
    ],
    "lr_decay_rate": 0.1,
    "batch_size": 16,
    "max_epochs": 300,
    "early_stop": 20,
    "use_cl": false,
    "cl_step_size": 2500,
    "model_args": {
        "num_nodes": 307,
        "in_steps": 12,
        "out_steps": 12,
        "steps_per_day": 288,
        "steps_per_week": 7,
        "input_dim": 3,
        "output_dim": 1,
        "input_embedding_dim": 24,
        "tod_embedding_dim": 24,
        "dow_embedding_dim": 24,
        "feed_forward_dim": 256,
        "num_heads": 4,
        "num_layers_t": 1,
        "num_layers_c": 1,
        "num_layers_s": 1,
        "num_layers_mlp": 2,
        "dropout": 0.1,
        "adaptive_embedding_dim": 80,
        "node_dim": 64,
        "use_temporal_heterogeneity": true,
        "use_spatial_heterogeneity": true,
        "use_temporal_cross": true,
        "use_spatial_cross": true,
        "use_mixed_proj": true
    }
}
==============================================================================================================
Layer (type:depth-idx)                                       Output Shape              Param #
==============================================================================================================
STHDformer                                                   [16, 12, 307, 1]          271,464
├─Linear: 1-1                                                [16, 12, 307, 24]         96
├─Embedding: 1-2                                             [16, 12, 307, 24]         6,912
├─Embedding: 1-3                                             [16, 12, 307, 24]         168
├─ModuleList: 1-9                                            --                        (recursive)
│    └─SelfAttentionLayer: 2-1                               [16, 12, 307, 152]        23,256
│    │    └─AttentionLayer: 3-1                              [16, 307, 12, 152]        93,024
│    │    └─Dropout: 3-2                                     [16, 307, 12, 152]        --
│    │    └─LayerNorm: 3-3                                   [16, 307, 12, 152]        304
│    │    └─Sequential: 3-4                                  [16, 307, 12, 152]        78,232
│    │    └─Dropout: 3-5                                     [16, 307, 12, 152]        --
│    │    └─LayerNorm: 3-6                                   [16, 307, 12, 152]        304
├─ModuleList: 1-5                                            --                        --
│    └─Temporal_Heterogeneity_SelfAttentionLayer: 2-2        [16, 12, 307, 152]        --
│    │    └─Temporal_Heterogeneity_AttentionLayer: 3-7       [16, 307, 12, 152]        93,072
│    │    └─Dropout: 3-8                                     [16, 307, 12, 152]        --
│    │    └─LayerNorm: 3-9                                   [16, 307, 12, 152]        304
│    │    └─Sequential: 3-10                                 [16, 307, 12, 152]        78,232
│    │    └─Dropout: 3-11                                    [16, 307, 12, 152]        --
│    │    └─LayerNorm: 3-12                                  [16, 307, 12, 152]        304
├─ModuleList: 1-11                                           --                        (recursive)
│    └─Cross_SelfAttentionLayer: 2-3                         [16, 12, 307, 152]        --
│    │    └─Cross_AttentionLayer: 3-13                       [16, 307, 12, 152]        93,024
│    │    └─Dropout: 3-14                                    [16, 307, 12, 152]        --
│    │    └─LayerNorm: 3-15                                  [16, 307, 12, 152]        304
│    │    └─Sequential: 3-16                                 [16, 307, 12, 152]        78,232
│    │    └─Dropout: 3-17                                    [16, 307, 12, 152]        --
│    │    └─LayerNorm: 3-18                                  [16, 307, 12, 152]        304
├─Dual_graph: 1-7                                            [16, 12, 307, 128]        --
│    └─Graph_projection: 2-4                                 [1, 307, 64]              --
│    │    └─Linear: 3-19                                     [1, 307, 64]              19,712
│    │    └─ReLU: 3-20                                       [1, 307, 64]              --
│    │    └─Dropout: 3-21                                    [1, 307, 64]              --
│    │    └─Linear: 3-22                                     [1, 307, 64]              4,160
│    └─Graph_projection: 2-5                                 [1, 307, 64]              --
│    │    └─Linear: 3-23                                     [1, 307, 64]              19,712
│    │    └─ReLU: 3-24                                       [1, 307, 64]              --
│    │    └─Dropout: 3-25                                    [1, 307, 64]              --
│    │    └─Linear: 3-26                                     [1, 307, 64]              4,160
├─Fusion_Model: 1-8                                          [16, 12, 307, 152]        --
│    └─Sequential: 2-6                                       [16, 12, 307, 80]         --
│    │    └─MLP: 3-27                                        [16, 12, 307, 208]        86,944
│    │    └─MLP: 3-28                                        [16, 12, 307, 208]        86,944
│    │    └─Linear: 3-29                                     [16, 12, 307, 80]         16,720
├─ModuleList: 1-9                                            --                        (recursive)
│    └─SelfAttentionLayer: 2-7                               [16, 12, 307, 152]        (recursive)
│    │    └─Sequential: 3-30                                 [16, 12, 307, 152]        23,256
│    │    └─AttentionLayer: 3-31                             [16, 12, 307, 152]        (recursive)
│    │    └─Dropout: 3-32                                    [16, 12, 307, 152]        --
│    │    └─LayerNorm: 3-33                                  [16, 12, 307, 152]        (recursive)
│    │    └─Sequential: 3-34                                 [16, 12, 307, 152]        (recursive)
│    │    └─Dropout: 3-35                                    [16, 12, 307, 152]        --
│    │    └─LayerNorm: 3-36                                  [16, 12, 307, 152]        (recursive)
├─ModuleList: 1-10                                           --                        --
│    └─Spatial_Heterogeneity_SelfAttentionLayer: 2-8         [16, 12, 307, 152]        --
│    │    └─Spatial_Heterogeneity_AttentionLayer: 3-37       [16, 12, 307, 152]        93,024
│    │    └─Dropout: 3-38                                    [16, 12, 307, 152]        --
│    │    └─LayerNorm: 3-39                                  [16, 12, 307, 152]        304
│    │    └─Sequential: 3-40                                 [16, 12, 307, 152]        78,232
│    │    └─Dropout: 3-41                                    [16, 12, 307, 152]        --
│    │    └─LayerNorm: 3-42                                  [16, 12, 307, 152]        304
├─ModuleList: 1-11                                           --                        (recursive)
│    └─Cross_SelfAttentionLayer: 2-9                         [16, 12, 307, 152]        (recursive)
│    │    └─Cross_AttentionLayer: 3-43                       [16, 12, 307, 152]        (recursive)
│    │    └─Dropout: 3-44                                    [16, 12, 307, 152]        --
│    │    └─LayerNorm: 3-45                                  [16, 12, 307, 152]        (recursive)
│    │    └─Sequential: 3-46                                 [16, 12, 307, 152]        (recursive)
│    │    └─Dropout: 3-47                                    [16, 12, 307, 152]        --
│    │    └─LayerNorm: 3-48                                  [16, 12, 307, 152]        (recursive)
├─Linear: 1-12                                               [16, 307, 12]             21,900
==============================================================================================================
Total params: 1,272,908
Trainable params: 1,272,908
Non-trainable params: 0
Total mult-adds (M): 20.43
==============================================================================================================
Input size (MB): 0.71
Forward/backward pass size (MB): 4271.48
Params size (MB): 3.91
Estimated Total Size (MB): 4276.10
==============================================================================================================

Loss: HuberLoss

